import pandas as pd
import numpy as np

def predict_choice_proportions(problem):

    def format_number(x):
        if isinstance(x, (int, float)):
            return f"{x:.2f}" if x != int(x) else str(int(x))
        return str(x)

    def _parse_option(problem, prefix, max_outcomes):
        ev = 0.0
        outcomes = []
        probs = []
        for i in range(1, max_outcomes + 1):
            outcome_key = f'{prefix}_outcome_{i}'
            prob_key = f'{prefix}_prob_{i}'
            raw_prob = problem.get(prob_key)
            outcome = pd.to_numeric(problem.get(outcome_key), errors='coerce')
            prob = pd.to_numeric(raw_prob, errors='coerce')
            if pd.notna(outcome) and pd.notna(prob):
                ev += outcome * prob
                outcomes.append(outcome)
                probs.append(prob)
        return ev, outcomes, probs

    for k in sorted(problem.keys()):
        v = problem[k]
        if pd.notna(v) and (k.startswith('A_') or k.startswith('B_')):
            print(f"  {k}: {format_number(v)}")

    # Step 1 & 2: Call the helper function to parse both options
    ev_a, outcomes_a, probs_a = _parse_option(problem, 'A', 3)
    ev_b, outcomes_b, probs_b = _parse_option(problem, 'B', 8)

    # Step 3: Apply behavioral heuristics to calculate subjective utility
    print("\n--- Applying Behavioral Heuristics ---")
    utility_a, utility_b = ev_a, ev_b
    all_outcomes = outcomes_a + outcomes_b
    max_abs_outcome = max(abs(o) for o in all_outcomes) if all_outcomes else 0
    is_certain_a = len(probs_a) == 1 and probs_a[0] == 1.0
    is_certain_b = len(probs_b) == 1 and probs_b[0] == 1.0
    
    print(f"Initial utilities: A=${format_number(utility_a)}, B=${format_number(utility_b)}")
    print(f"Max absolute outcome: ${format_number(max_abs_outcome)}")
    print(f"Certainty: A={is_certain_a}, B={is_certain_b}")

    # Heuristics for gains and losses
    is_gain_domain = all(o >= 0 for o in all_outcomes) if all_outcomes else False
    has_losses = any(o < 0 for o in all_outcomes)
    
    print(f"\nDomain Analysis:")
    print(f"- Gain domain only: {is_gain_domain}")
    print(f"- Contains losses: {has_losses}")

    if is_gain_domain and is_certain_a and max_abs_outcome > 10:
        old_utility = utility_a
        utility_a *= 1.25
        print(f"\n[Certainty Effect] A's utility: ${format_number(old_utility)} → ${format_number(utility_a)} (25% bonus)")

    if has_losses:
        lambda_factor = 1.05 + 1.2 * (min(max_abs_outcome, 1000) / 1000)
        print(f"\n[Loss Aversion] Applying general λ = {lambda_factor:.2f} to all losses")
        
        def value_function(x):
            return x * lambda_factor if x < 0 else x
        
        old_utility_a, old_utility_b = ev_a, ev_b
        utility_a = sum(value_function(o) * p for o, p in zip(outcomes_a, probs_a))
        utility_b = sum(value_function(o) * p for o, p in zip(outcomes_b, probs_b))
        
        print(f"  A's utility: ${format_number(old_utility_a)} → ${format_number(utility_a)}")
        print(f"  B's utility: ${format_number(old_utility_b)} → ${format_number(utility_b)}")

        is_certain_loss_a = is_certain_a and outcomes_a and outcomes_a[0] < 0
        is_risky_loss_b = not is_certain_b and outcomes_b and all(o <= 0 for o in outcomes_b)

        if is_certain_loss_a and is_risky_loss_b:
            # breakeven effect or big loss effect
            if utility_a == utility_b or max_abs_outcome > 10:
                risk_seeking_factor = 0.80
                old_utility = utility_b
                utility_b *= risk_seeking_factor
                print(f"\n[Certainty Effect for Losses] B's utility: ${format_number(old_utility)} → ${format_number(utility_b)}")


    # Splitting Effect
    positive_outcomes_a = sum(1 for o in outcomes_a if o > 0)
    positive_outcomes_b = sum(1 for o in outcomes_b if o > 0)
    if not is_certain_a and not is_certain_b and is_gain_domain and positive_outcomes_b > 1 and positive_outcomes_a > 1:
        high_value_threshold = max_abs_outcome * 0.8
        high_value_count_a = sum(1 for o in outcomes_a if o >= high_value_threshold)
        high_value_count_b = sum(1 for o in outcomes_b if o >= high_value_threshold)
        if high_value_count_b > high_value_count_a:
            old_utility = utility_b
            utility_b *= 1.10
            print(f"\n[Splitting Effect] B's utility: ${format_number(old_utility)} → ${format_number(utility_b)}")
            print(f"  High-value threshold: ${format_number(high_value_threshold)}")
            print(f"  High-value outcomes - A: {high_value_count_a}, B: {high_value_count_b}")

    positive_outcomes_b = sum(1 for o in outcomes_b if o > 0)
    is_lottery_b = any(0 < p < 0.01 for p in probs_b)

    # The Lottery Effect should only apply to SIMPLE gambles (e.g., 1 or 2 positive outcomes)
    if is_certain_a and is_lottery_b and positive_outcomes_b <= 2:
        jackpot = max(outcomes_b, default=0)
        certain_payout = outcomes_a[0]
        if jackpot > 20 * certain_payout:
            utility_b *= 1.5
            print(f"\n[Lottery Effect] B's utility: ${format_number(old_utility)} → ${format_number(utility_b)}")

    # Step 4: Convert final utilities into choice proportions
    print("\n--- Calculating Final Probabilities ---")
    print(f"Final utilities: A=${format_number(utility_a)}, B=${format_number(utility_b)}")
    
    total_abs_ev = abs(ev_a) + abs(ev_b)
    if total_abs_ev == 0: total_abs_ev = 1

    k = 0.5 / np.log1p(total_abs_ev)
    print(f"Softmax temperature: k = {k:.4f}")

    try:
        exp_diff = np.exp(k * (utility_b - utility_a))
        prop_a = 1 / (1 + exp_diff)
        print(f"exp(k*(B-A)) = {exp_diff:.4f}")
    except OverflowError:
        prop_a = 0.0 if utility_b > utility_a else 1.0
        print(f"[Warning] Overflow in exp calculation, using prop_a = {prop_a:.4f}")
    
    print(f"\nFinal choice probabilities:")
    print(f"  P(Choose A): {prop_a:.4f}")
    print(f"  P(Choose B): {1-prop_a:.4f}")
    print("\n=== End of Prediction ===")
    
    return (prop_a, 1 - prop_a)